{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "8A-7-9jXuF29"
      ],
      "authorship_tag": "ABX9TyMfb5JQ10sGCeIQn5Xcwu0f"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**NASA-Inspired Research Assistant & Retrocompatibility Validation**\n",
        "\n",
        "Copyright 2025, Denis Rothman\n",
        "\n",
        "**Goal:** This notebook serves a dual purpose. Its primary goal is to demonstrate our fully upgraded Chapter 7 Context Engine as a complete, functional application: the **NASA-Inspired Research Assistant**. We will also perform rigorous validation by running **backward compatibility tests** for the key workflows from Chapters 5 and 6. This process showcases not only the engine's new capabilities for verifiability and security but also its stability as an evolving, enterprise-grade system.\n",
        "\n",
        "This notebook demonstrates the following key capabilities:\n",
        "\n",
        "* **System Validation & Backward Compatibility:** Before testing the new features, we will run the key workflows from previous chapters to prove that our latest upgrades have not compromised existing functionality, demonstrating the stability of our modular architecture.\n",
        "\n",
        "* **High-Fidelity RAG in Action:** See the upgraded `Researcher` agent retrieve information from our new knowledge base and programmatically generate citations for its claims.\n",
        "\n",
        "* **Agent Defenses at Work:** Observe how the `helper_sanitize_input` function provides a silent but essential layer of security, protecting the engine from potentially tainted data.\n",
        "\n",
        "* **Complex, Dynamic Planning:** Analyze the technical trace to deconstruct the sophisticated, multi-step plan the `Planner` autonomously creates to answer a multi-faceted research question.\n",
        "\n",
        "* **Verifiable, End-to-End Output:** The final result will be a clear, synthesized answer followed by a list of the source documents used, proving the system is not just powerful, but trustworthy."
      ],
      "metadata": {
        "id": "hfzZQTDjpfu6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I. Inititalization"
      ],
      "metadata": {
        "id": "zo-XYpI5f3JX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GitHub"
      ],
      "metadata": {
        "id": "a455hFQaWMUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Downloading files from public repository...\")\n",
        "\n",
        "# The -f flag tells curl to fail on an error (like 404)\n",
        "!curl -Lf https://raw.githubusercontent.com/Denis2054/Context-Engineering/main/commons/ch7/utils.py --output utils.py\n",
        "!curl -Lf https://raw.githubusercontent.com/Denis2054/Context-Engineering/main/commons/ch7/helpers.py --output helpers.py\n",
        "!curl -Lf https://raw.githubusercontent.com/Denis2054/Context-Engineering/main/commons/ch7/agents.py --output agents.py\n",
        "!curl -Lf https://raw.githubusercontent.com/Denis2054/Context-Engineering/main/commons/ch7/registry.py --output registry.py\n",
        "!curl -Lf https://raw.githubusercontent.com/Denis2054/Context-Engineering/main/commons/ch7/engine.py --output engine.py\n",
        "# (You might want to add a check here to see if the files actually exist now)\n",
        "print(\"âœ… File download attempt finished!\")"
      ],
      "metadata": {
        "id": "tAVwhKSLQXxy",
        "outputId": "b43099af-4c46-40e5-9f78-b49350b404e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading files from public repository...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1825  100  1825    0     0   7625      0 --:--:-- --:--:-- --:--:--  7635\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  5337  100  5337    0     0  23195      0 --:--:-- --:--:-- --:--:-- 23305\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  9432  100  9432    0     0  41604      0 --:--:-- --:--:-- --:--:-- 41734\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  3611  100  3611    0     0  11737      0 --:--:-- --:--:-- --:--:-- 11762\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  7431  100  7431    0     0  24701      0 --:--:-- --:--:-- --:--:-- 24687\n",
            "âœ… File download attempt finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation and client setup"
      ],
      "metadata": {
        "id": "8A-7-9jXuF29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Installation and Client Setup\n",
        "\n",
        "# Import the setup functions from your new utility file\n",
        "import utils\n",
        "\n",
        "# Run the installation\n",
        "utils.install_dependencies()\n",
        "\n",
        "# Initialize the OpenAI and Pinecone clients\n",
        "client, pc = utils.initialize_clients()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkx_Oxy7gerq",
        "outputId": "fdc451a9-e41b-4084-efb3-2686d99cf5c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Installing required packages...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Context Engine library Import"
      ],
      "metadata": {
        "id": "BYvkF-c9pVn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Import the hardened helper functions (LLM, Embeddings, Pinecone)\n",
        "import helpers\n",
        "\n",
        "# 2. Import the specialist agent functions (Librarian, Researcher, Writer)\n",
        "import agents\n",
        "\n",
        "# 3. Import the AGENT_TOOLKIT object that knows about all the agents\n",
        "from registry import AGENT_TOOLKIT\n",
        "\n",
        "# 4. Import the main context_engine function that orchestrates the entire process\n",
        "from engine import context_engine"
      ],
      "metadata": {
        "id": "P7wL-SSlpfcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Engine Room"
      ],
      "metadata": {
        "id": "8XDZmds95dBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === ENGINE ROOM: The Main Execution Function ===\n",
        "# This function contains all the logic to run the engine.\n",
        "# We define it here so our final cell can be very simple.\n",
        "\n",
        "import logging\n",
        "import pprint\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "def execute_and_display(goal, config, client, pc):\n",
        "    \"\"\"\n",
        "    Runs the context engine with a given goal and configuration,\n",
        "    then displays the final output and the technical trace.\n",
        "    \"\"\"\n",
        "    logging.info(f\"******** Starting Engine for Goal: '{goal}' **********\\n\")\n",
        "\n",
        "    # 1. Run the Context Engine using the provided configuration\n",
        "    result, trace = context_engine(\n",
        "        goal,\n",
        "        client=client,\n",
        "        pc=pc,\n",
        "        **config  # Unpack the config dictionary into keyword arguments\n",
        "    )\n",
        "\n",
        "    # 2. Display the Final Result for the main reader\n",
        "    print(\"--- FINAL OUTPUT ---\")\n",
        "    if result:\n",
        "        display(Markdown(result))\n",
        "    else:\n",
        "        print(f\"The engine failed to produce a result. Status: {trace.status}\")\n",
        "\n",
        "    # 3. Display the Technical Trace for the developer/technical reader\n",
        "    print(\"\\n\\n--- TECHNICAL TRACE (for the tech reader) ---\")\n",
        "    if trace:\n",
        "        print(f\"Trace Status: {trace.status}\")\n",
        "        print(f\"Total Duration: {trace.duration:.2f} seconds\")\n",
        "        print(\"Execution Steps:\")\n",
        "        # Use pprint for a clean, readable dictionary output\n",
        "        pp = pprint.PrettyPrinter(indent=2)\n",
        "        pp.pprint(trace.steps)"
      ],
      "metadata": {
        "id": "-ExOs7K95Vgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Control Deck configuration"
      ],
      "metadata": {
        "id": "mQnaOOy-0ds9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define all configuration variables for this run in a dictionary\n",
        "config = {\n",
        "    \"index_name\": 'genai-mas-mcp-ch3',\n",
        "    \"generation_model\": \"gpt-5\",\n",
        "    \"embedding_model\": \"text-embedding-3-small\",\n",
        "    \"namespace_context\": 'ContextLibrary',\n",
        "    \"namespace_knowledge\": 'KnowledgeStore'\n",
        "}"
      ],
      "metadata": {
        "id": "08ghrgVs0ZAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#II.CONTROL DECK\n",
        "\n",
        "=== CONTROL DECK: Define Goal and Run Engine ===\n",
        "This is the main interactive cell.\n",
        "1. Change the 'goal' variable to your desired task.\n",
        "2. Run this cell.\n"
      ],
      "metadata": {
        "id": "Q16NN3RpuQ40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Chapter 7: CONTROL DECK: NASA Research Assistant\n",
        "\n",
        "# 1. Define a research goal that requires verifiable, cited answers.\n",
        "goal = \"What are the primary scientific objectives of the Juno mission, and what makes its design unique? Please cite your sources.\"\n",
        "\n",
        "# 2. Use the standard configuration\n",
        "config = {\n",
        "    \"index_name\": 'genai-mas-mcp-ch3',\n",
        "    \"generation_model\": \"gpt-5\", # or your preferred model\n",
        "    \"embedding_model\": \"text-embedding-3-small\",\n",
        "    \"namespace_context\": 'ContextLibrary',\n",
        "    \"namespace_knowledge\": 'KnowledgeStore'\n",
        "}\n",
        "\n",
        "# 3. Call the execution function\n",
        "execute_and_display(goal, config, client, pc)"
      ],
      "metadata": {
        "id": "4EC3HmWihJUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Chapter 6 CONTROL DECK: Context Reduction Workflow\n",
        "\n",
        "# 1. Define a large piece of text that would be expensive or too long\n",
        "# to use as direct context for the Writer agent.\n",
        "large_text_from_researcher = \"\"\"\n",
        "Juno is a NASA space probe orbiting the planet Jupiter. It was launched from Cape Canaveral Air Force Station on August 5, 2011, as part of the New Frontiers program. Juno entered a polar orbit of Jupiter on July 5, 2016, to begin a scientific investigation of the planet. After completing its primary mission, it received a mission extension. Juno's mission is to measure Jupiter's composition, gravitational field, magnetic field, and polar magnetosphere. It is also searching for clues about how the planet formed, including whether it has a rocky core, the amount of water present within the deep atmosphere, mass distribution, and its deep winds, which can reach speeds up to 618 kilometers per hour (384 mph). Juno is the second spacecraft to orbit Jupiter, after the nuclear-powered Galileo orbiter, which orbited from 1995 to 2003. Unlike all earlier spacecraft to the outer planets, Juno is powered by solar arrays, which are commonly used by satellites orbiting Earth and working in the inner Solar System, whereas radioisotope thermoelectric generators are commonly used for missions to the outer Solar System and beyond. For Juno, however, the three largest solar array wings ever deployed on a planetary probe play an integral role in stabilizing the spacecraft and generating power.\n",
        "\"\"\"\n",
        "\n",
        "# 2. Define a goal that requires both using the large text AND a creative step.\n",
        "# This forces the Planner to recognize the need for summarization before writing.\n",
        "goal = f\"\"\"First, summarize the following text about the Juno probe to extract only the key facts about its scientific mission and instruments. Then, using that summary, write a short, suspenseful scene for a children's story about the probe's dangerous arrival at Jupiter.\n",
        "\n",
        "--- TEXT TO USE ---\n",
        "{large_text_from_researcher}\n",
        "\"\"\"\n",
        "\n",
        "# 3. Use the same configuration dictionary\n",
        "config = {\n",
        "    \"index_name\": 'genai-mas-mcp-ch3',\n",
        "    \"generation_model\": \"gpt-5\", # or your preferred model\n",
        "    \"embedding_model\": \"text-embedding-3-small\",\n",
        "    \"namespace_context\": 'ContextLibrary',\n",
        "    \"namespace_knowledge\": 'KnowledgeStore'\n",
        "}\n",
        "\n",
        "# 4. Call the execution function\n",
        "execute_and_display(goal, config, client, pc)"
      ],
      "metadata": {
        "id": "f830Ay5RFsU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Chapter 5 Writing a story\n",
        "# Define the high-level goal\n",
        "goal = \"Write a short, suspenseful scene for a children's story about the Apollo 11 moon landing, highlighting the danger.\"\n",
        "# Call the execution function from the cell above\n",
        "execute_and_display(goal, config, client, pc)"
      ],
      "metadata": {
        "id": "FCAqbBbt5uqh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}