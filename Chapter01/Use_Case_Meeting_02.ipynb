{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# A Meeting Analysis Use Case\n",
        "\n",
        "Copyright 2025-2026, Denis Rothman\n",
        "\n",
        "The notebook's goal is to demonstrate how to guide an AI through a multi-step analytical process, moving from a raw transcript to actionable insights, thereby training both the user and the AI.\n",
        "\n",
        "This notebook is a step-by-step guide on how you can engineer a structured context . This guide will serve as the architectural blueprint for your code, explaining not just the *what* but the *why* at each stage.\n"
      ],
      "metadata": {
        "id": "FDBDBUKfSggD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### Setup and Preliminaries\n",
        "\n",
        "This section handles the basic configuration.\n",
        "\n",
        "1.  **Cell 1: Install Libraries**\n",
        "\n",
        "      * Install the necessary OpenAI library."
      ],
      "metadata": {
        "id": "ivJQbp_mwtDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Installation\n",
        "!pip install tqdm==4.67.1 --upgrade\n",
        "!pip install openai==2.14.0"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Collecting openai==2.14.0\n",
            "  Downloading openai-2.14.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai==2.14.0) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai==2.14.0) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai==2.14.0) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai==2.14.0) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai==2.14.0) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai==2.14.0) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai==2.14.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai==2.14.0) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai==2.14.0) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai==2.14.0) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai==2.14.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==2.14.0) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai==2.14.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai==2.14.0) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai==2.14.0) (0.4.2)\n",
            "Downloading openai-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 2.12.0\n",
            "    Uninstalling openai-2.12.0:\n",
            "      Successfully uninstalled openai-2.12.0\n",
            "Successfully installed openai-2.14.0\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "id": "voHBQKGtSggF",
        "outputId": "1368f6f9-5eaa-4fbb-d166-ef8e0571ab71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  **Cell 2: Imports and API Key**\n",
        "\n",
        "      * Import the library and securely prompt for the user's API key. This is better than hard-coding it."
      ],
      "metadata": {
        "id": "jtGvDLpLSggG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Imports and API Key Setup\n",
        "# We will use the OpenAI library to interact with the LLM and Google Colab's\n",
        "# secret manager to securely access your API key.\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# Load the API key from Colab secrets, set the env var, then init the client\n",
        "try:\n",
        "    api_key = userdata.get(\"API_KEY\")\n",
        "    if not api_key:\n",
        "        raise userdata.SecretNotFoundError(\"API_KEY not found.\")\n",
        "\n",
        "    # Set environment variable for downstream tools/libraries\n",
        "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "    # Create client (will read from OPENAI_API_KEY)\n",
        "    client = OpenAI()\n",
        "    print(\"OpenAI API key loaded and environment variable set successfully.\")\n",
        "\n",
        "except userdata.SecretNotFoundError:\n",
        "    print('Secret \"API_KEY\" not found.')\n",
        "    print('Please add your OpenAI API key to the Colab Secrets Manager.')\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the API key: {e}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API key loaded and environment variable set successfully.\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "id": "eNHm5qkhSggG",
        "outputId": "3daf1570-645a-49e5-fade-4a292e455787",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.  **Cell 3: The Raw Data (The \"Crime Scene\")**\n",
        "\n",
        "      * Define the meeting transcript as a multi-line string. This is our primary data source."
      ],
      "metadata": {
        "id": "Vgp62z7OSggG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell 3: The Full Workshop Transcript\n",
        "meeting_transcript = \"\"\"\n",
        "        Alex: Alright, let’s get started! I hope everyone grabbed some of those mini-donuts in the breakroom. I think I’ve had three already, so I’m officially on a sugar high.\n",
        "        Jamie: They’re dangerous, Alex. Anyway, I’m ready when you are.\n",
        "        Sam: Same here. My calendar is clear for the next two hours.\n",
        "        Alex: Great. So, the goal of this workshop is to finalize our \"Lumina Design System\" core components. First up: the Primary Button component. Jamie, I saw your note about the hover states?\n",
        "        Jamie: Yeah, the current spec uses a 15% lighten filter for the hover state. It looks fine on Chrome, but it’s rendering inconsistently on some legacy mobile browsers. It’s a mess to maintain.\n",
        "        Sam: Legacy browsers? I thought we were phasing those out?\n",
        "        Jamie: We are, but we still have that one government contract that requires IE11 support for another six months.\n",
        "        Sam: Right, the \"Directorate\" account. Okay, we can't break that. What’s the fix?\n",
        "        Jamie: I suggest we move away from filters and just define a specific HEX code for the hover state. It’s more manual work for me to set up, but it’s bulletproof across all browsers.\n",
        "        Alex: That makes sense. Let’s do it. Jamie, can you map those HEX codes by Friday?\n",
        "        Jamie: I can try. I’m a bit swamped with the login page bug, but if I can get some help with the documentation, I can get it done.\n",
        "        Sam: I can actually have our intern, Leo, help with the documentation part. He’s looking for a project.\n",
        "        Alex: Perfect. Let’s tentatively assign the documentation to Leo, overseen by Jamie. Now, second topic: The Icon Library. We’re currently using \"FontAwesome,\" but the licensing cost is going up next month.\n",
        "        Sam: I saw that invoice. It’s a 40% jump! I’m not sure the budget can handle that right now.\n",
        "        Jamie: We could switch to an open-source library like \"Lucide\" or \"Phosphor.\" They’re free, but it would mean a full audit of every icon in the current app to make sure they match.\n",
        "        Alex: (Sighs) That’s a massive undertaking. We have over 200 icons.\n",
        "        Sam: What if we do a hybrid? We keep FontAwesome for the complex dashboard icons for now, but use Phosphor for all new features.\n",
        "        Alex: I think that's a recipe for a visual disaster, Sam. The styles won't match. I’d actually propose we dedicate a \"Sprint Zero\" next month just to migrate everything to Lucide. It’s a one-time pain for long-term savings.\n",
        "        Sam: I like the sound of \"long-term savings.\" If Alex says the design will be cleaner, I’m on board. Let’s plan for that migration in the Q3 kickoff.\n",
        "        Alex: Excellent. I’ll draft the migration roadmap. Okay, that’s the big stuff. Who wants the last donut?\n",
        "        Jamie: I think I’m good. I need to go look at those HEX codes before my next meeting.\n",
        "        \"\"\"\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "id": "UJpZUVXpSggG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### Layer 1: Establishing the scope (The 'What')\n",
        "\n",
        "Here, we define the scope of the analysis. Each step's output will inform the next, creating a chain of context.\n",
        "\n",
        "1.  **Cell 4: g2 - Set the Signal-to-Noise Ratio**\n",
        "\n",
        "      * We'll start by cleaning the data. The prompt explicitly tells the AI to separate substantive content from conversational noise."
      ],
      "metadata": {
        "id": "40PTjmLaSggH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: g2 - Isolating Content from Noise\n",
        "prompt_g2 = f\"\"\"\n",
        "        Analyze the following meeting transcript. Your task is to isolate the substantive content from the conversational noise.\n",
        "        - Substantive content includes: decisions made, project updates, problems raised, and strategic suggestions.\n",
        "        - Noise includes: greetings, pleasantries, and off-topic remarks (like coffee).\n",
        "        Return ONLY the substantive content.\n",
        "\n",
        "        Transcript:\n",
        "        ---\n",
        "        {meeting_transcript}\n",
        "        ---\n",
        "        \"\"\""
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "id": "069eAXt9SggH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "try:\n",
        "    client = OpenAI()\n",
        "\n",
        "    response_g2 = client.chat.completions.create(\n",
        "        model=\"gpt-5.2\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt_g2}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    substantive_content = response_g2.choices[0].message.content\n",
        "    print(\"--- SUBSTANTIVE CONTENT ---\")\n",
        "    print(substantive_content)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "ptfVZHlps3r4",
        "outputId": "220a2d22-ef6c-42db-e638-e76a73294d06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- SUBSTANTIVE CONTENT ---\n",
            "- Workshop goal: finalize the **Lumina Design System** core components.\n",
            "\n",
            "- **Primary Button hover state**\n",
            "  - Problem: current hover spec uses a **15% lighten filter** that renders inconsistently on **legacy mobile browsers** and is hard to maintain.\n",
            "  - Constraint: must maintain **IE11 support for six more months** due to the **Directorate (government) contract**.\n",
            "  - Decision: **replace filter-based hover styling with explicit HEX hover colors** for cross-browser consistency.\n",
            "  - Action items:\n",
            "    - **Jamie** to map hover-state **HEX codes by Friday** (pending workload).\n",
            "    - **Leo (intern)** assigned to help with **documentation**, overseen by **Jamie**.\n",
            "\n",
            "- **Icon Library**\n",
            "  - Update/Problem: **FontAwesome licensing cost increases 40% next month**, creating budget pressure.\n",
            "  - Options discussed:\n",
            "    - Switch to open-source (**Lucide** or **Phosphor**) but requires auditing/matching **200+ icons**.\n",
            "    - Hybrid approach (keep FontAwesome for some, use Phosphor for new) was rejected due to visual inconsistency risk.\n",
            "  - Decision: run a dedicated **“Sprint Zero” next month** to **migrate all icons to Lucide** for long-term cost savings and design consistency.\n",
            "  - Plan: include migration in the **Q3 kickoff**.\n",
            "  - Action item: **Alex** to draft the **migration roadmap**.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  **Cell 5: g3 - Define the Scope of Time (Simulated RAG)**\n",
        "\n",
        "      * We'll simulate a RAG context by providing a \"previous\" summary and asking for what's new. This teaches the user the importance of historical context."
      ],
      "metadata": {
        "id": "XY2ZlN8sSggH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: g3 - Identifying NEW Information (Simulated RAG)\n",
        "previous_summary = \"In our last meeting, we finalized the goals for Project Phoenix and assigned backend work to Tom and front-end to Maria.\"\n",
        "\n",
        "prompt_g3 = f\"\"\"\n",
        "Context: The summary of our last meeting was: \"{previous_summary}\"\n",
        "\n",
        "Task: Analyze the following substantive content from our new meeting. Identify and summarize ONLY the new developments, problems, or decisions that have occurred since the last meeting.\n",
        "\n",
        "New Meeting Content:\n",
        "---\n",
        "{substantive_content}\n",
        "---\n",
        "\"\"\"\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "# Your chat completion request\n",
        "try:\n",
        "    response_g3 = client.chat.completions.create(\n",
        "        model=\"gpt-5.2\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt_g3}]\n",
        "    )\n",
        "    new_developments = response_g3.choices[0].message.content\n",
        "    print(\"--- NEW DEVELOPMENTS SINCE LAST MEETING ---\")\n",
        "    print(new_developments)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- NEW DEVELOPMENTS SINCE LAST MEETING ---\n",
            "- **Scope/Focus shift:** The workshop’s goal is now to finalize the **Lumina Design System** core components (new initiative not mentioned last time).\n",
            "\n",
            "- **Primary Button hover state (new problem + decision):**\n",
            "  - **Problem identified:** A **15% lighten filter** in the hover spec renders inconsistently on **legacy mobile browsers** and is difficult to maintain.\n",
            "  - **Constraint noted:** Must keep **IE11 support for 6 more months** due to a **Directorate (government) contract**.\n",
            "  - **Decision made:** Replace the filter-based hover styling with **explicit HEX hover colors** to ensure cross-browser consistency.\n",
            "  - **New action items:**  \n",
            "    - **Jamie** to map hover-state **HEX codes by Friday** (pending workload).  \n",
            "    - **Leo (intern)** to assist with **documentation**, overseen by **Jamie**.\n",
            "\n",
            "- **Icon Library (new problem + decision):**\n",
            "  - **Problem identified:** **FontAwesome licensing costs** are increasing **40% next month**, creating budget pressure.\n",
            "  - **Decision made:** Do a dedicated **“Sprint Zero” next month** to **migrate all icons to Lucide** (open-source) for cost savings and consistency; **hybrid approach was rejected** due to visual inconsistency risk.\n",
            "  - **Plan update:** The migration will be included in the **Q3 kickoff**.\n",
            "  - **New action item:** **Alex** to draft the **icon migration roadmap**.\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "id": "1LhMAk4-SggH",
        "outputId": "a7402caf-ebe2-42d5-eb34-efb070ca82ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### Layer 2: Conducting the Investigation (The 'How')\n",
        "\n",
        "Now we move from identifying facts to generating insights, the core of the semantic context interpreation journey.\n",
        "\n",
        "1.  **Cell 6: g4 - Identify the Key Threads**\n",
        "\n",
        "      * This is a crucial step. The prompt asks the AI to read between the lines."
      ],
      "metadata": {
        "id": "wh2UWr4ySggI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: g4 - Uncovering Implicit Threads\n",
        "prompt_g4 = f\"\"\"\n",
        "Task: Analyze the following meeting content for implicit social dynamics and unstated feelings. Go beyond the literal words.\n",
        "- Did anyone seem hesitant or reluctant despite agreeing to something?\n",
        "- Were there any underlying disagreements or tensions?\n",
        "- What was the overall mood?\n",
        "\n",
        "Meeting Content:\n",
        "---\n",
        "{substantive_content}\n",
        "---\n",
        "\"\"\"\n",
        "try:\n",
        "    response_g4 = client.chat.completions.create(\n",
        "        model=\"gpt-5.2\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt_g4}]\n",
        "    )\n",
        "    implicit_threads = response_g4.choices[0].message.content\n",
        "    print(\"--- IMPLICIT THREADS AND DYNAMICS ---\")\n",
        "    print(implicit_threads)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- IMPLICIT THREADS AND DYNAMICS ---\n",
            "### Hesitation / reluctance (despite agreement)\n",
            "\n",
            "- **Jamie’s Friday deadline reads as a soft commitment.** The parenthetical “*(pending workload)*” is a classic hedge: Jamie agreed to the action, but is signaling capacity risk and protecting themselves from being held to a hard date. That suggests reluctance to own a tight turnaround or frustration with current load—without openly pushing back.\n",
            "- **Assigning Leo (intern) “to help with documentation, overseen by Jamie” subtly increases Jamie’s burden.** Even if framed as help, “overseen by Jamie” implies mentorship/review overhead. Jamie may not have objected in the moment, but the structure hints at a dynamic where work is delegated downward while accountability remains with Jamie—often accepted outwardly, felt as extra weight privately.\n",
            "- **The IE11 constraint likely produced unspoken resignation.** “Must maintain IE11 support… due to the Directorate contract” is a non-negotiable external force. The group appears to comply, but this kind of requirement commonly triggers silent annoyance because it blocks more modern, cleaner approaches.\n",
            "\n",
            "### Underlying disagreements or tensions\n",
            "\n",
            "- **Maintainability vs. compliance tension:**  \n",
            "  The hover-state issue isn’t just technical. It’s the team wanting a maintainable, modern spec while being forced into legacy compatibility. Nobody is “wrong,” but it creates ongoing friction: design/engineering ideals vs. contractual reality.\n",
            "- **Budget pressure is driving technical/design strategy.**  \n",
            "  The FontAwesome licensing increase (“40% next month”) introduces financial urgency. Even if everyone agreed on migrating to Lucide, the subtext is that the decision is at least partly coerced by budget—so any team members who preferred FontAwesome may have deferred rather than fight a cost-driven directive.\n",
            "- **“Hybrid rejected” suggests a prior split that got shut down.**  \n",
            "  Hybrid approaches are often proposed by pragmatists trying to reduce scope/risk. Rejecting it for “visual inconsistency risk” implies the group chose purity/consistency over incrementalism. That can leave a lingering tension: some people may feel the all-at-once migration is riskier or heavier, but the decision favored the design-system ideal.\n",
            "- **Potential status/ownership dynamic:**  \n",
            "  Alex is tasked with drafting the roadmap (strategic planning), while Jamie gets time-sensitive execution plus oversight of an intern. That division can hint at an implicit hierarchy: Alex shaping direction, Jamie carrying delivery load. Even if normal, it can breed quiet resentment if workloads aren’t balanced.\n",
            "\n",
            "### Overall mood\n",
            "\n",
            "- **Pragmatic, slightly pressured, and compliance-driven.**  \n",
            "  The tone is “make it work reliably across constraints” rather than exploratory or creative. Two big external pressures—**IE11 contractual support** and **licensing cost increases**—set a mood of constraint management.\n",
            "- **Decisive, but with undercurrent of strain.**  \n",
            "  Clear decisions were made (explicit HEX, full migration via Sprint Zero), which suggests forward motion. But the hedged deadline and the need for a dedicated migration sprint imply the team feels time/budget strain and is trying to contain risk with planning rituals (roadmap, Sprint Zero, Q3 kickoff integration).\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "id": "Tkb3x_cnSggI",
        "outputId": "4991fbd0-ff41-45d4-b7f0-f6b106bd830a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  **Cell 7: g5 - Perform \"Intellectual Combinations\"**\n",
        "\n",
        "      * Here, we prompt the AI to be creative and solve a problem by synthesizing different ideas from the meeting."
      ],
      "metadata": {
        "id": "yyd_EZ5HSggI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: g5 - Generating a Novel Solution\n",
        "prompt_g5 = f\"\"\"\n",
        "Context: In the meeting, Maria suggested a 'soft launch' to avoid server strain, and also mentioned her team has 'extra bandwidth'.\n",
        "Tom is facing a 3-day delay on the backend.\n",
        "\n",
        "Task: Propose a novel, actionable idea that uses Maria's team's extra bandwidth to help mitigate Tom's 3-day delay. Combine these two separate pieces of information into a single solution.\n",
        "\"\"\"\n",
        "try:\n",
        "    response_g5 = client.chat.completions.create(\n",
        "        model=\"gpt-5.2\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt_g5}]\n",
        "    )\n",
        "    novel_solution = response_g5.choices[0].message.content\n",
        "    print(\"--- NOVEL SOLUTION PROPOSED BY AI ---\")\n",
        "    print(novel_solution)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- NOVEL SOLUTION PROPOSED BY AI ---\n",
            "Have Maria’s team use their extra bandwidth to build a **“soft-launch backend shim”** that reduces the amount of backend work needed on day one, letting you launch a limited version while Tom finishes the full backend over the next 3 days.\n",
            "\n",
            "**Actionable plan**\n",
            "1. **Define the soft-launch scope (today, 30–60 mins):** Agree on a small set of read-only or low-risk flows (e.g., browse, view details, limited onboarding) and cap traffic (invite-only, % rollout, or feature-flagged).\n",
            "2. **Maria’s team implements a temporary adapter layer (today–tomorrow):**\n",
            "   - Stand up a lightweight **API gateway / BFF (backend-for-frontend)** or edge function that:\n",
            "     - Serves **stubbed responses** for endpoints Tom hasn’t finished (using static fixtures or a small temporary datastore).\n",
            "     - Routes completed endpoints to Tom’s existing services.\n",
            "     - Adds **aggressive caching** and request throttling to reduce server strain during the soft launch.\n",
            "3. **Front-end + QA alignment (parallel):** Maria’s team provides a stable contract (OpenAPI/spec + mock server) so the client can integrate without waiting for Tom’s final endpoints.\n",
            "4. **Swap-in plan (day 3):** When Tom’s backend work lands, replace stubbed routes with real ones behind the same gateway, keeping the soft-launch throttles/caching until full rollout.\n",
            "\n",
            "**Why this mitigates the 3-day delay**\n",
            "- You can **launch earlier** with controlled load (soft launch) while Tom completes the backend.\n",
            "- The shim absorbs missing functionality and **prevents server strain** via caching/throttling.\n",
            "- Tom can ship without rushing; Maria’s team “bridges” the gap and then cleanly hands off by swapping implementations behind feature flags/routing.\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "id": "8JN5E5X4SggI",
        "outputId": "cfcf2400-f448-4222-bf5b-d09e29050c1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### Layer 3: Determining the Action (The 'What Next')\n",
        "\n",
        "Finally, we turn the analysis into concrete, forward-looking artifacts.\n",
        "\n",
        "1.  **Cell 8: g6 - Define the Output Format (Final Summary)**\n",
        "\n",
        "      * We compile all the key information into a structured, final summary, showing the importance of clear outputs."
      ],
      "metadata": {
        "id": "J0CD-ztrSggI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: g6 - Creating the Final, Structured Summary\n",
        "prompt_g6 = f\"\"\"\n",
        "Task: Create a final, concise summary of the meeting in a markdown table.\n",
        "Use the following information to construct the table.\n",
        "\n",
        "- New Developments: {new_developments}\n",
        "\n",
        "The table should have three columns: \"Topic\", \"Decision/Outcome\", and \"Owner\".\n",
        "\"\"\"\n",
        "try:\n",
        "    response_g6 = client.chat.completions.create(\n",
        "        model=\"gpt-5.2\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt_g6}]\n",
        "    )\n",
        "    final_summary_table = response_g6.choices[0].message.content\n",
        "    print(\"--- FINAL MEETING SUMMARY TABLE ---\")\n",
        "    print(final_summary_table)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- FINAL MEETING SUMMARY TABLE ---\n",
            "| Topic | Decision/Outcome | Owner |\n",
            "|---|---|---|\n",
            "| Workshop scope/focus | Shifted goal to finalize **Lumina Design System** core components (new initiative). | Team |\n",
            "| Primary Button hover state | Replaced **15% lighten filter** hover styling with **explicit HEX hover colors** for cross-browser consistency (must maintain **IE11 support for 6 more months** due to Directorate contract). | Jamie (HEX mapping); Leo (documentation support under Jamie) |\n",
            "| Icon Library | Run **“Sprint Zero” next month** to migrate all icons from **FontAwesome to Lucide** (open-source); **hybrid approach rejected**. Migration included in **Q3 kickoff**. | Alex (migration roadmap) |\n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "id": "xXRnPWuESggI",
        "outputId": "d7122340-9edd-40f6-8e3e-e70ddf842750",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  **Cell 9: g7 - Generate the Subsequent Task**\n",
        "\n",
        "      * The last step is to use the analysis to perform a real-world action, closing the loop from insight to action."
      ],
      "metadata": {
        "id": "jk1g9wVvSggI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: g7 - Drafting the Follow-Up Action\n",
        "prompt_g7 = f\"\"\"\n",
        "Task: Based on the following summary table, draft a polite and professional follow-up email to the team (Sarah, Tom, Maria).\n",
        "The email should clearly state the decisions made and the action items for each person.\n",
        "\n",
        "Summary Table:\n",
        "---\n",
        "{final_summary_table}\n",
        "---\n",
        "\"\"\"\n",
        "try:\n",
        "    response_g7 = client.chat.completions.create(\n",
        "        model=\"gpt-5.2\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt_g7}]\n",
        "    )\n",
        "    follow_up_email = response_g7.choices[0].message.content\n",
        "    print(\"--- DRAFT FOLLOW-UP EMAIL ---\")\n",
        "    print(follow_up_email)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- DRAFT FOLLOW-UP EMAIL ---\n",
            "Subject: Follow-up: Workshop decisions + action items (Lumina Design System)\n",
            "\n",
            "Hi Sarah, Tom, and Maria,  \n",
            "\n",
            "Thanks again for the discussion. I’m writing to recap the key decisions and confirm the action items/owners.\n",
            "\n",
            "**Decisions confirmed**\n",
            "- **Workshop scope/focus:** We’ve shifted the workshop goal to finalize the **Lumina Design System** *core components* (new initiative).\n",
            "- **Primary Button hover state:** We will replace the **15% lighten filter** hover styling with **explicit HEX hover colors** to ensure cross-browser consistency. We also need to **maintain IE11 support for the next 6 months** due to the Directorate contract.\n",
            "- **Icon Library:** We will run a **“Sprint Zero” next month** to migrate all icons from **FontAwesome to Lucide** (open-source). The **hybrid approach is rejected**, and the migration will be included in the **Q3 kickoff**.\n",
            "\n",
            "**Action items**\n",
            "- **Sarah / Tom / Maria (Team):** Align on the updated workshop objective and ensure upcoming sessions prioritize **Lumina core component finalization**.\n",
            "- **Jamie:** Produce the **HEX hover color mapping** for the Primary Button (and any related states as needed) with **IE11 compatibility** in mind.\n",
            "- **Leo:** Support Jamie by **updating/maintaining documentation** for the new explicit HEX hover colors (under Jamie’s direction).\n",
            "- **Alex:** Draft the **Sprint Zero migration roadmap** (FontAwesome → Lucide), covering approach, sequencing, and how it plugs into the **Q3 kickoff**.\n",
            "\n",
            "If anything above doesn’t match your understanding, please reply with corrections. Otherwise, we’ll proceed on this plan.\n",
            "\n",
            "Best regards,  \n",
            "[Your Name]\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "id": "aQ1PzmTlSggI",
        "outputId": "27c3f2dd-cf46-4a87-ae27-1e919ea64fb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook structure doesn't just \"get a summary.\" It takes the user on a journey, showing them *how* to think with the AI as a partner. It perfectly translates the abstract \"Scope, Investigation, Action\" framework into a repeatable, educational, and powerful process."
      ],
      "metadata": {
        "id": "-tDIxvHSSggJ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}